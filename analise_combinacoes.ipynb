{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÃLISE DE COMBINAÃ‡Ã•ES - Definir Hierarquias\n",
    "\n",
    "Objetivo: Ver que combinaÃ§Ãµes de cÃ³digos existem no mesmo dia/colaborador APÃ“S remover incompatibilidades, para definir regras de prioridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('Carregando dados...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar dados\n",
    "df_raw = pd.read_csv('combined_data.csv')\n",
    "df_raw['Data'] = pd.to_datetime(df_raw['Data'])\n",
    "\n",
    "print(f'Total registos: {len(df_raw):,}')\n",
    "print(f'Colaboradores: {df_raw[\"login_colaborador\"].nunique():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aplicar nova classificaÃ§Ã£o\n",
    "df_codigos = pd.read_excel('cÃ³digos_V2.xlsx')\n",
    "\n",
    "df = df_raw.merge(\n",
    "    df_codigos,\n",
    "    left_on='segmento_processado_codigo',\n",
    "    right_on='Codigo Segmento',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f'âœ“ ClassificaÃ§Ã£o aplicada')\n",
    "print(f'Registos com classificaÃ§Ã£o: {df[\"Nivel 1\"].notna().sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. REMOVER INCOMPATIBILIDADES (copiar lÃ³gica do notebook principal)\n",
    "print('Criando matriz de compatibilidade...')\n",
    "\n",
    "# Matriz de compatibilidade Nivel 2\n",
    "compat_matrix = pd.DataFrame([\n",
    "    # Trabalho Pago\n",
    "    ['PresenÃ§a', 'Atraso', 1],\n",
    "    ['PresenÃ§a', 'FormaÃ§Ã£o', 1],\n",
    "    \n",
    "    # Incompatibilidades principais\n",
    "    ['PresenÃ§a', 'AusÃªncia MÃ©dica', 0],\n",
    "    ['PresenÃ§a', 'AusÃªncia Injustificada', 0],\n",
    "    ['PresenÃ§a', 'LicenÃ§a Mat/Pat', 0],\n",
    "    ['PresenÃ§a', 'FÃ©rias', 0],\n",
    "    ['PresenÃ§a', 'Falta Justificada', 0],\n",
    "    \n",
    "    ['Trabalho Pago', 'AusÃªncia MÃ©dica', 0],\n",
    "    ['Trabalho Pago', 'AusÃªncia Injustificada', 0],\n",
    "    ['Trabalho Pago', 'Falta Injustificada', 0],\n",
    "], columns=['cat1', 'cat2', 'compativel'])\n",
    "\n",
    "compat_dict = {}\n",
    "for _, row in compat_matrix.iterrows():\n",
    "    key1 = tuple(sorted([row['cat1'], row['cat2']]))\n",
    "    compat_dict[key1] = row['compativel']\n",
    "\n",
    "print(f'âœ“ Matriz criada: {len(compat_dict)} regras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Identificar dias duplicados\n",
    "print('Identificando dias com mÃºltiplos registos...')\n",
    "\n",
    "dias_duplicados = df.groupby(['login_colaborador', 'Data']).size()\n",
    "dias_duplicados = dias_duplicados[dias_duplicados > 1].reset_index()\n",
    "dias_duplicados.columns = ['login_colaborador', 'Data', 'num_registos']\n",
    "\n",
    "print(f'Dias com mÃºltiplos registos: {len(dias_duplicados):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 5. Testar incompatibilidades (VERSÃƒO OTIMIZADA)\nprint('Testando incompatibilidades nos dias duplicados...\\n')\n\n# PRÃ‰-FILTRAR apenas dias duplicados\ndias_dup_list = list(zip(dias_duplicados['login_colaborador'], dias_duplicados['Data']))\ndf_dup = df[df.set_index(['login_colaborador', 'Data']).index.isin(dias_dup_list)].copy()\n\nprint(f'   Registos a testar: {len(df_dup):,}')\n\n# PRÃ‰-AGRUPAR dados (UMA vez!)\ndf_dup_grouped = df_dup.groupby(['login_colaborador', 'Data']).agg({\n    'Nivel 2': lambda x: list(x.dropna().unique()),\n    'segmento_processado_codigo': lambda x: list(x.unique()),\n    'nome_colaborador': 'first'\n}).reset_index()\n\ndf_dup_grouped.columns = ['login_colaborador', 'Data', 'categorias_nivel2', 'codigos', 'nome']\n\nprint(f'   Dias Ãºnicos a testar: {len(df_dup_grouped):,}')\n\n# Identificar incompatibilidades\nprint('\\nTestando pares de categorias...')\ndias_incompativeis = []\n\nfor idx, row in df_dup_grouped.iterrows():\n    if idx % 5000 == 0 and idx > 0:\n        print(f'   Processados {idx:,}/{len(df_dup_grouped):,} dias...')\n\n    login = row['login_colaborador']\n    data = row['Data']\n    categorias = row['categorias_nivel2']\n    codigos = row['codigos']\n    nome = row['nome']\n\n    # Testar todos os pares\n    incompativel_encontrado = False\n    pares_incompativeis = []\n\n    for i, cat1 in enumerate(categorias):\n        for cat2 in categorias[i+1:]:\n            key = tuple(sorted([cat1, cat2]))\n            if key in compat_dict and compat_dict[key] == 0:\n                incompativel_encontrado = True\n                pares_incompativeis.append(f'{cat1} + {cat2}')\n\n    if incompativel_encontrado:\n        dias_incompativeis.append({\n            'login_colaborador': login,\n            'Data': data,\n            'nome_colaborador': nome,\n            'categorias': ', '.join(categorias),\n            'codigos': ', '.join(codigos),\n            'pares_incompativeis': ' | '.join(pares_incompativeis)\n        })\n\ndf_incompativeis = pd.DataFrame(dias_incompativeis)\n\nprint(f'\\nâœ“ Teste concluÃ­do')\nprint(f'ðŸ”´ INCOMPATIBILIDADES ENCONTRADAS: {len(df_incompativeis)}')\n\nif len(df_incompativeis) > 0:\n    print(f'\\nPrimeiros 10 casos:')\n    print(df_incompativeis[['Data', 'nome_colaborador', 'pares_incompativeis']].head(10))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. REMOVER incompatibilidades\n",
    "print('Removendo dias incompatÃ­veis...')\n",
    "\n",
    "if len(df_incompativeis) > 0:\n",
    "    df_limpo = df.copy()\n",
    "    \n",
    "    for _, incompat in df_incompativeis.iterrows():\n",
    "        mask = (df_limpo['login_colaborador'] == incompat['login_colaborador']) & \\\n",
    "               (df_limpo['Data'] == incompat['Data'])\n",
    "        df_limpo = df_limpo[~mask]\n",
    "    \n",
    "    print(f'âœ“ Removidos {len(df) - len(df_limpo):,} registos')\n",
    "    print(f'âœ“ Dataset limpo: {len(df_limpo):,} registos')\n",
    "else:\n",
    "    df_limpo = df.copy()\n",
    "    print('âœ“ Nenhuma incompatibilidade - dataset limpo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ANÃLISE DE COMBINAÃ‡Ã•ES\n",
    "\n",
    "Agora que removemos incompatibilidades, vamos ver que combinaÃ§Ãµes RESTAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Identificar dias AINDA com mÃºltiplos registos (apÃ³s limpeza)\n",
    "print('=== COMBINAÃ‡Ã•ES APÃ“S REMOVER INCOMPATIBILIDADES ===\\n')\n",
    "\n",
    "dias_multiplos = df_limpo.groupby(['login_colaborador', 'Data']).size()\n",
    "dias_multiplos = dias_multiplos[dias_multiplos > 1].reset_index()\n",
    "dias_multiplos.columns = ['login_colaborador', 'Data', 'num_registos']\n",
    "\n",
    "print(f'Dias com mÃºltiplos registos (compatÃ­veis): {len(dias_multiplos):,}')\n",
    "print(f'Total registos nesses dias: {dias_multiplos[\"num_registos\"].sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. EXTRAIR todas as combinaÃ§Ãµes que existem\n",
    "print('\\nExtraindo combinaÃ§Ãµes de Nivel 1...\\n')\n",
    "\n",
    "combinacoes = []\n",
    "\n",
    "for _, dia in dias_multiplos.iterrows():\n",
    "    login = dia['login_colaborador']\n",
    "    data = dia['Data']\n",
    "    \n",
    "    registos_dia = df_limpo[(df_limpo['login_colaborador'] == login) & (df_limpo['Data'] == data)]\n",
    "    \n",
    "    # Pegar Nivel 1\n",
    "    nivel1_list = registos_dia['Nivel 1'].dropna().unique().tolist()\n",
    "    nivel2_list = registos_dia['Nivel 2'].dropna().unique().tolist()\n",
    "    \n",
    "    # Criar string ordenada\n",
    "    nivel1_str = ' + '.join(sorted(nivel1_list))\n",
    "    nivel2_str = ' + '.join(sorted(nivel2_list))\n",
    "    \n",
    "    combinacoes.append({\n",
    "        'login_colaborador': login,\n",
    "        'Data': data,\n",
    "        'num_registos': len(registos_dia),\n",
    "        'combinacao_nivel1': nivel1_str,\n",
    "        'combinacao_nivel2': nivel2_str\n",
    "    })\n",
    "\n",
    "df_combinacoes = pd.DataFrame(combinacoes)\n",
    "\n",
    "print(f'Total de casos com combinaÃ§Ãµes: {len(df_combinacoes):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. CONTAR frequÃªncia de cada combinaÃ§Ã£o (Nivel 1)\n",
    "print('\\nðŸ“Š FREQUÃŠNCIA DAS COMBINAÃ‡Ã•ES (NIVEL 1):\\n')\n",
    "\n",
    "freq_nivel1 = df_combinacoes['combinacao_nivel1'].value_counts()\n",
    "\n",
    "print(f'Total de combinaÃ§Ãµes Ãºnicas: {len(freq_nivel1)}\\n')\n",
    "print('Top 20 combinaÃ§Ãµes mais frequentes:\\n')\n",
    "\n",
    "for idx, (comb, count) in enumerate(freq_nivel1.head(20).items(), 1):\n",
    "    pct = count / len(df_combinacoes) * 100\n",
    "    print(f'{idx:2d}. {comb:60s}: {count:6,} casos ({pct:5.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. CONTAR frequÃªncia de cada combinaÃ§Ã£o (Nivel 2)\n",
    "print('\\nðŸ“Š FREQUÃŠNCIA DAS COMBINAÃ‡Ã•ES (NIVEL 2):\\n')\n",
    "\n",
    "freq_nivel2 = df_combinacoes['combinacao_nivel2'].value_counts()\n",
    "\n",
    "print(f'Total de combinaÃ§Ãµes Ãºnicas: {len(freq_nivel2)}\\n')\n",
    "print('Top 20 combinaÃ§Ãµes mais frequentes:\\n')\n",
    "\n",
    "for idx, (comb, count) in enumerate(freq_nivel2.head(20).items(), 1):\n",
    "    pct = count / len(df_combinacoes) * 100\n",
    "    print(f'{idx:2d}. {comb:60s}: {count:6,} casos ({pct:5.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Exportar para Excel para anÃ¡lise detalhada\n",
    "print('\\nExportando para Excel...\\n')\n",
    "\n",
    "# Sheet 1: Resumo de frequÃªncias Nivel 1\n",
    "freq_nivel1_df = freq_nivel1.reset_index()\n",
    "freq_nivel1_df.columns = ['CombinaÃ§Ã£o Nivel 1', 'FrequÃªncia']\n",
    "freq_nivel1_df['Percentagem'] = (freq_nivel1_df['FrequÃªncia'] / len(df_combinacoes) * 100).round(2)\n",
    "\n",
    "# Sheet 2: Resumo de frequÃªncias Nivel 2\n",
    "freq_nivel2_df = freq_nivel2.reset_index()\n",
    "freq_nivel2_df.columns = ['CombinaÃ§Ã£o Nivel 2', 'FrequÃªncia']\n",
    "freq_nivel2_df['Percentagem'] = (freq_nivel2_df['FrequÃªncia'] / len(df_combinacoes) * 100).round(2)\n",
    "\n",
    "# Sheet 3: Detalhes de todos os casos\n",
    "df_combinacoes_export = df_combinacoes.merge(\n",
    "    df_limpo[['login_colaborador', 'Data', 'nome_colaborador']].drop_duplicates(),\n",
    "    on=['login_colaborador', 'Data'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Exportar\n",
    "with pd.ExcelWriter('analise_combinacoes.xlsx', engine='openpyxl') as writer:\n",
    "    freq_nivel1_df.to_excel(writer, sheet_name='Frequencias_Nivel1', index=False)\n",
    "    freq_nivel2_df.to_excel(writer, sheet_name='Frequencias_Nivel2', index=False)\n",
    "    df_combinacoes_export.to_excel(writer, sheet_name='Detalhes', index=False)\n",
    "\n",
    "print('âœ“ Exportado: analise_combinacoes.xlsx')\n",
    "print('\\n  Sheet 1: Frequencias_Nivel1 - Resumo por Nivel 1')\n",
    "print('  Sheet 2: Frequencias_Nivel2 - Resumo por Nivel 2')\n",
    "print('  Sheet 3: Detalhes - Todos os casos com combinaÃ§Ãµes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PRÃ“XIMO PASSO\n",
    "\n",
    "Abre o ficheiro **analise_combinacoes.xlsx** e define as **regras de prioridade** para cada combinaÃ§Ã£o encontrada.\n",
    "\n",
    "Exemplo:\n",
    "- `Atraso + Trabalho Pago` â†’ Para absentismo: Trabalho Pago | Para atrasos: Atraso\n",
    "- `AusÃªncia + Trabalho Pago` â†’ ??? (define a regra)\n",
    "- etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}