{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Absentismo - Call Center\n",
    "\n",
    "**Objetivo:** Análise descritiva e prescritiva de padrões de absentismo.\n",
    "\n",
    "**Dataset:** 1.3M registos, 3,135 colaboradores, 18 meses (2024-01 a 2025-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GRUPO 1: PREPARAÇÃO E LIMPEZA DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Bibliotecas carregadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Carregar dados\n",
    "print('PASSO 1.1: Carregar dados')\n",
    "print('-' * 70)\n",
    "\n",
    "# Dataset principal\n",
    "df_raw = pd.read_csv('combined_data.csv')\n",
    "df_raw['Data'] = pd.to_datetime(df_raw['Data'])\n",
    "\n",
    "print(f'Dataset carregado:')\n",
    "print(f'  Registos: {len(df_raw):,}')\n",
    "print(f'  Colaboradores: {df_raw[\"login_colaborador\"].nunique():,}')\n",
    "print(f'  Periodo: {df_raw[\"Data\"].min().date()} ate {df_raw[\"Data\"].max().date()}')\n",
    "\n",
    "# Nova classificação\n",
    "df_codigos = pd.read_excel('códigos_V2.xlsx')\n",
    "\n",
    "print(f'\\nClassificacao carregada:')\n",
    "print(f'  Codigos: {len(df_codigos)}')\n",
    "print(f'  Nivel 1 (categorias): {df_codigos[\"Nivel 1\"].nunique()}')\n",
    "print(f'  Nivel 2 (subcategorias): {df_codigos[\"Nivel 2\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Aplicar classificação\n",
    "print('\\nPASSO 1.2: Aplicar classificacao')\n",
    "print('-' * 70)\n",
    "\n",
    "df = df_raw.merge(\n",
    "    df_codigos,\n",
    "    left_on='segmento_processado_codigo',\n",
    "    right_on='Codigo Segmento',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Verificar mapeamento\n",
    "sem_classificacao = df['Nivel 1'].isna().sum()\n",
    "\n",
    "if sem_classificacao == 0:\n",
    "    print('OK: Todos os codigos mapeados')\n",
    "else:\n",
    "    print(f'AVISO: {sem_classificacao} registos sem classificacao')\n",
    "\n",
    "print(f'\\nTotal registos: {len(df):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Identificar incompatibilidades\n",
    "print('\\nPASSO 1.3: Identificar incompatibilidades')\n",
    "print('-' * 70)\n",
    "\n",
    "# Matriz de compatibilidade (Nivel 2)\n",
    "compat_rules = pd.DataFrame([\n",
    "    # Compativeis\n",
    "    ['Presença', 'Atraso', 1],\n",
    "    ['Presença', 'Formação', 1],\n",
    "    \n",
    "    # Incompativeis\n",
    "    ['Presença', 'Ausência Médica', 0],\n",
    "    ['Presença', 'Ausência Injustificada', 0],\n",
    "    ['Presença', 'Licença Mat/Pat', 0],\n",
    "    ['Presença', 'Férias', 0],\n",
    "    ['Presença', 'Falta Justificada', 0],\n",
    "    ['Presença', 'Ferias / Feriado / Folga', 0],\n",
    "    ['Trabalho Pago', 'Ausência Médica', 0],\n",
    "    ['Trabalho Pago', 'Falta Injustificada', 0],\n",
    "], columns=['cat1', 'cat2', 'compativel'])\n",
    "\n",
    "# Criar dicionário\n",
    "compat_dict = {}\n",
    "for _, row in compat_rules.iterrows():\n",
    "    key = tuple(sorted([row['cat1'], row['cat2']]))\n",
    "    compat_dict[key] = row['compativel']\n",
    "\n",
    "print(f'Regras de compatibilidade: {len(compat_dict)}')\n",
    "\n",
    "# Identificar dias com multiplos registos\n",
    "dias_mult = df.groupby(['login_colaborador', 'Data']).size()\n",
    "dias_mult = dias_mult[dias_mult > 1].reset_index()\n",
    "dias_mult.columns = ['login_colaborador', 'Data', 'num_registos']\n",
    "\n",
    "print(f'\\nDias com multiplos registos: {len(dias_mult):,}')\n",
    "\n",
    "# Pre-filtrar e agrupar (otimizado)\n",
    "dias_mult_idx = list(zip(dias_mult['login_colaborador'], dias_mult['Data']))\n",
    "df_mult = df[df.set_index(['login_colaborador', 'Data']).index.isin(dias_mult_idx)]\n",
    "\n",
    "df_mult_grouped = df_mult.groupby(['login_colaborador', 'Data']).agg({\n",
    "    'Nivel 2': lambda x: list(x.dropna().unique()),\n",
    "    'segmento_processado_codigo': lambda x: list(x.unique()),\n",
    "    'nome_colaborador': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(f'Dias unicos a testar: {len(df_mult_grouped):,}')\n",
    "\n",
    "# Testar pares\n",
    "print('\\nTestando incompatibilidades...')\n",
    "incompativeis = []\n",
    "\n",
    "for idx, row in df_mult_grouped.iterrows():\n",
    "    if idx % 10000 == 0 and idx > 0:\n",
    "        print(f'  Processados {idx:,}/{len(df_mult_grouped):,}')\n",
    "    \n",
    "    categorias = row['Nivel 2']\n",
    "    pares_incompat = []\n",
    "    \n",
    "    for i, cat1 in enumerate(categorias):\n",
    "        for cat2 in categorias[i+1:]:\n",
    "            key = tuple(sorted([cat1, cat2]))\n",
    "            if key in compat_dict and compat_dict[key] == 0:\n",
    "                pares_incompat.append(f'{cat1} + {cat2}')\n",
    "    \n",
    "    if pares_incompat:\n",
    "        incompativeis.append({\n",
    "            'login_colaborador': row['login_colaborador'],\n",
    "            'Data': row['Data'],\n",
    "            'nome_colaborador': row['nome_colaborador'],\n",
    "            'categorias': ', '.join(categorias),\n",
    "            'pares_incompativeis': ' | '.join(pares_incompat)\n",
    "        })\n",
    "\n",
    "df_incompativeis = pd.DataFrame(incompativeis)\n",
    "\n",
    "print(f'\\nRESULTADO: {len(df_incompativeis)} dias incompativeis encontrados')\n",
    "\n",
    "if len(df_incompativeis) > 0:\n",
    "    print('\\nDistribuicao por tipo de incompatibilidade:')\n",
    "    \n",
    "    # Contar cada par\n",
    "    todos_pares = []\n",
    "    for pares_str in df_incompativeis['pares_incompativeis']:\n",
    "        todos_pares.extend(pares_str.split(' | '))\n",
    "    \n",
    "    pares_count = pd.Series(todos_pares).value_counts()\n",
    "    \n",
    "    for par, count in pares_count.items():\n",
    "        print(f'  {par:50s}: {count:3d} casos')\n",
    "    \n",
    "    # Exportar\n",
    "    df_incompativeis.to_excel('incompatibilidades_detalhadas.xlsx', index=False)\n",
    "    print('\\nExportado: incompatibilidades_detalhadas.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Remover dias incompativeis\n",
    "print('\\nPASSO 1.4: Remover dias incompativeis')\n",
    "print('-' * 70)\n",
    "\n",
    "if len(df_incompativeis) > 0:\n",
    "    # Criar indice para remover\n",
    "    idx_remover = df.set_index(['login_colaborador', 'Data']).index.isin(\n",
    "        list(zip(df_incompativeis['login_colaborador'], df_incompativeis['Data']))\n",
    "    )\n",
    "    \n",
    "    registos_removidos = idx_remover.sum()\n",
    "    \n",
    "    df_limpo = df[~idx_remover].copy()\n",
    "    \n",
    "    print(f'Registos removidos: {registos_removidos:,}')\n",
    "    print(f'Dataset limpo: {len(df_limpo):,} registos')\n",
    "else:\n",
    "    df_limpo = df.copy()\n",
    "    print('Nenhum registo a remover')\n",
    "    print(f'Dataset limpo: {len(df_limpo):,} registos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Separar dataframes\n",
    "print('\\nPASSO 1.5: Separar dataframes')\n",
    "print('-' * 70)\n",
    "\n",
    "# df_atrasos: todos os registos onde Nivel 1 = 'Atraso'\n",
    "# Objetivo: contar numero de DIAS com atraso (nao precisa agregar)\n",
    "df_atrasos = df_limpo[df_limpo['Nivel 1'] == 'Atraso'].copy()\n",
    "\n",
    "print(f'df_atrasos criado:')\n",
    "print(f'  Registos: {len(df_atrasos):,}')\n",
    "print(f'  Dias unicos: {df_atrasos.groupby([\"login_colaborador\", \"Data\"]).ngroups:,}')\n",
    "print(f'  Colaboradores: {df_atrasos[\"login_colaborador\"].nunique():,}')\n",
    "\n",
    "# df_absentismo: todos os registos EXCETO atrasos\n",
    "# Vai ser agregado com hierarquias\n",
    "df_absentismo = df_limpo[df_limpo['Nivel 1'] != 'Atraso'].copy()\n",
    "\n",
    "print(f'\\ndf_absentismo (antes agregacao):')\n",
    "print(f'  Registos: {len(df_absentismo):,}')\n",
    "print(f'  Colaboradores: {df_absentismo[\"login_colaborador\"].nunique():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Agregar df_absentismo com hierarquias\n",
    "print('\\nPASSO 1.6: Agregar df_absentismo')\n",
    "print('-' * 70)\n",
    "\n",
    "# Verificar se ainda ha dias duplicados\n",
    "dias_dup_abs = df_absentismo.groupby(['login_colaborador', 'Data']).size()\n",
    "dias_dup_abs = dias_dup_abs[dias_dup_abs > 1]\n",
    "\n",
    "print(f'Dias com multiplos registos: {len(dias_dup_abs):,}')\n",
    "\n",
    "if len(dias_dup_abs) > 0:\n",
    "    # Ver combinacoes que existem\n",
    "    print('\\nCombinacoes existentes (Nivel 1):')\n",
    "    \n",
    "    dias_dup_idx = dias_dup_abs.index.tolist()\n",
    "    df_dup_abs = df_absentismo.set_index(['login_colaborador', 'Data']).loc[dias_dup_idx].reset_index()\n",
    "    \n",
    "    combos = df_dup_abs.groupby(['login_colaborador', 'Data'])['Nivel 1'].apply(\n",
    "        lambda x: ' + '.join(sorted(x.unique()))\n",
    "    ).value_counts()\n",
    "    \n",
    "    for combo, count in combos.items():\n",
    "        print(f'  {combo:50s}: {count:,} dias')\n",
    "\n",
    "# Regras de agregacao\n",
    "# Hierarquia: manter codigo mais relevante para absentismo\n",
    "# (strings ordenadas para consistencia)\n",
    "agg_rules = {\n",
    "    'nome_colaborador': 'first',\n",
    "    'categoria_profissional': 'first',\n",
    "    'segmento_processado_codigo': lambda x: ', '.join(sorted(x.unique())),\n",
    "    'Nivel 1': lambda x: ', '.join(sorted(x.unique())),\n",
    "    'Nivel 2': lambda x: ', '.join(sorted(x.unique())),\n",
    "}\n",
    "\n",
    "# Campos opcionais\n",
    "for col in ['operacao', 'Activo?', 'DtActivacao', 'DtDesactivacao']:\n",
    "    if col in df_absentismo.columns:\n",
    "        agg_rules[col] = 'first'\n",
    "\n",
    "# Agregar\n",
    "df_absentismo = df_absentismo.groupby(['login_colaborador', 'Data']).agg(agg_rules).reset_index()\n",
    "\n",
    "print(f'\\ndf_absentismo (apos agregacao):')\n",
    "print(f'  Dias-colaborador: {len(df_absentismo):,}')\n",
    "print(f'  Colaboradores: {df_absentismo[\"login_colaborador\"].nunique():,}')\n",
    "print(f'  Periodo: {df_absentismo[\"Data\"].min().date()} ate {df_absentismo[\"Data\"].max().date()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.7 Validacao final\n",
    "print('\\nPASSO 1.7: Validacao final')\n",
    "print('=' * 70)\n",
    "\n",
    "# Check 1: df_absentismo sem duplicados\n",
    "dup_abs = df_absentismo.groupby(['login_colaborador', 'Data']).size()\n",
    "dup_abs = dup_abs[dup_abs > 1]\n",
    "\n",
    "print('\\n1. Dias duplicados em df_absentismo:')\n",
    "if len(dup_abs) == 0:\n",
    "    print('   OK: Nenhum dia duplicado')\n",
    "else:\n",
    "    print(f'   ERRO: {len(dup_abs)} dias duplicados')\n",
    "\n",
    "# Check 2: df_absentismo sem atrasos\n",
    "tem_atraso = df_absentismo[df_absentismo['Nivel 1'].str.contains('Atraso', na=False)]\n",
    "\n",
    "print('\\n2. Atrasos em df_absentismo:')\n",
    "if len(tem_atraso) == 0:\n",
    "    print('   OK: Nenhum atraso')\n",
    "else:\n",
    "    print(f'   ERRO: {len(tem_atraso)} registos com atraso')\n",
    "\n",
    "# Check 3: df_atrasos so tem atrasos\n",
    "sem_atraso = df_atrasos[df_atrasos['Nivel 1'] != 'Atraso']\n",
    "\n",
    "print('\\n3. Registos sem atraso em df_atrasos:')\n",
    "if len(sem_atraso) == 0:\n",
    "    print('   OK: Todos os registos sao atrasos')\n",
    "else:\n",
    "    print(f'   ERRO: {len(sem_atraso)} registos sem atraso')\n",
    "\n",
    "# Resumo\n",
    "print('\\n' + '=' * 70)\n",
    "print('RESUMO GRUPO 1:')\n",
    "print('=' * 70)\n",
    "print(f'\\nDataset original     : {len(df_raw):,} registos')\n",
    "print(f'Incompatibilidades   : {len(df_incompativeis)} dias removidos')\n",
    "print(f'\\ndf_absentismo        : {len(df_absentismo):,} dias-colaborador')\n",
    "print(f'                       ({df_absentismo[\"login_colaborador\"].nunique():,} colaboradores)')\n",
    "print(f'\\ndf_atrasos           : {len(df_atrasos):,} registos')\n",
    "print(f'                       ({df_atrasos.groupby([\"login_colaborador\", \"Data\"]).ngroups:,} dias unicos)')\n",
    "print(f'                       ({df_atrasos[\"login_colaborador\"].nunique():,} colaboradores)')\n",
    "print('\\n' + '=' * 70)\n",
    "print('Grupo 1 concluido - Dados prontos para analise')\n",
    "print('=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
